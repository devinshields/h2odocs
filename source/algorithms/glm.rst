
Generalized Linear Model (GLM)
------------------------------

GLM includes several, flexible algorithms. Each serves a different
purpose. Depending on function choice, it can be used either 
for prediction or classification.

When to use GLM 
"""""""""""""""

The variable of interest relates to  predictions or inferences
about a rate, an event, or a continuous measurement. Questions are
about how a set of environmental conditions
influence that variable. Here are some examples:

  "What attributes make my customers distinct from the population as a whole?"

  "Given a set of specific manufacturing conditions, how many units produced will fail?"

  "What conditions most influence whether a client contacts our support service?"


Quick step-by-step
""""""""""""""""""
       
#. Import data. Under the drop down menu Data choose from the options
   listed, and follow the import helper.
  

#. Parse data. Once data have been imported choose SUBMIT (a button on
   the page).  When parse finishes the page redirects to output of a
   data frame with summary statistics and the H2O assigned .hex key  


#. Specify a model. Model options are listed both at the top of the
   page displaying parsed data, as well as under the drop down menu
   Model. Select GLM. 


#. Destination Key can be left blank and will be automatically
   generated, or can be user specified.


#. Key is required and is the .hex previously generated for the source
   data. 


#. Once key has been correctly entered, specify a Y (dependent
   variable) using the drop down menu.


#. From the list of X variables choose those relevant to analysis by
   highlighting them. 


#. Choose the appropriate regression family for the type of dependent variable
   being predicted. 


#. Tuning parameters lambda, alpha, and alternative link functions can be
   defined, however it is not necessary for the analysis to run.


#.  Press SUBMIT.  

  
Scoring and predicting
""""""""""""""""""""""
      
To score a model: 
     
#. Import and parse a testing data set composed of the same predictor
   variables utilized in building the original model. 


#. Under the drop down menu Score select GLM.


#. In model key enter the .hex key generated when the model was
   built. Model key can be found in Admin drop down menu by
   selecting Jobs and choosing the correct model from the list. 


#. In hex key enter the key associated with the testing data set. 


#. Adjust thresholds if needed (for binomial models).


#. Press submit


Notes on scoring: Model scoring is used to test the predictive ability
of the generated model. In general, given 100% of the available data,
a training set (the data used to build the predictive model) consists
of 90% of the data, and the testing set consists of 10%. The model
score is generated by comparing predicted values to the actual values
and calculating a rate of correct predictions. 

Predicting
""""""""""
 
#. Parse the data on which you would like to predict. Note that this
   data should have the same variables as those used in generating the
   model to be applied. 

#. Under the drop down menu Score select Predict
   
#. Enter the destination key for your model (which can be found under
   Jobs in the Admin drop down menu if needed), and the .hex key for
   the data to be predicted on. 

#. Press Submit

#. The resulting column is a row by row match with the data submitted,
   giving a predicted value. This output can be downloaded and saved
   as a .csv file. 



Defining a GLM model
""""""""""""""""""""

  Y: Dependent variable (DV).
	
  X:  field will auto populate with. The set of X are the independent
  variables on which the model predicts.
  

  Family and link:  Each of the given options differs in the
  assumptions made about the Y variable - the target of
  prediction. Each family is associated with a default link function,
  which defines the specialized transformation on the set of X
  variables chosen to  predict Y. 	

  Gaussian (identity): (Y) are quantitative, continuous (or continuous
  predicted values can be meaningfully interpreted), and expected to
  be normally distributed 

  Binomial (logit): dependent variables take on two values,
  traditionally coded as 0 and 1, and follow a binomial distribution,
  can be understood as a categorical Y with two possible outcomes

  Poisson (log): dependent variable is a count - a quantitative,
  discrete value that expresses the number of times some event occurred

  Gamma (inverse): dependent variable is a survival measure

  Lambda: H2O provides a default value, but this can also be user
  defined. Lambda is a regularization parameter that is designed to
  prevent overfitting. The best value(s) of lambda depends on the
  desired level of agreement. 

  Alpha: A user defined tuning regularization parameter that H2O sets
  to 0.5 by default, but which can take any value between 0 and 1,
  inclusive.  It functions so that there is an added penalty taken
  against the estimated fit of the model as the number of parameters
  increases. An alpha of 1 is the lasso penalty, and an alpha of 0 is
  the ridge penalty.
 
  Weight: Allows the user to specify consideration given to
  observations based on the observed Y value. Weight=1 is
  neutral. Weight = 0.5 treats negative examples as twice more
  important than positive ones. Weight = 2.0 does the opposite.

  Case and Casemode: used in combination, where a threshold value in
  the Y variable can be specified, and the model can be asked to
  predict for observations above, below, or equal to this value. Used
  in binomial prediction, where the default case is the mean of the Y column.  

Interpreting a Model
""""""""""""""""""""

  n: the number of observations (also called examples). Each
  observation is one row.

  p: the number of estimated parameters. Each additional piece of
  information you ask H2O to estimate increases p by one. 

  Degrees of Freedom: Null (total) is defined as (n-1) to account for the
  condition that the residuals 	must sum to zero. 

  Residual is (n-1)-p : the null degrees of freedom less the number of
  parameters you are estimating in your model. Deviance: The
  difference between the predicted value and the observed value for
  each example or observation in the data. 
	
  Null Deviance: associated with the full model
 
  Residual Deviance: associated with the reduced model

  AIC: A model selection criterial that penalizes models having large
  numbers of predictors. AIC stands for Akiaike information
  criterion. It is defined as AIC = n ln SSEp - n ln n + 2p

  AUC: stands for Area Under Curve. The curve in question is the
  receiver operating characteristic curve. The criteria is a commonly
  used metric for evaluating the performance of classifier models. It
  gives the probability that a randomly chosen positive observation is
  correctly ranked greater than a randomly chosen negative
  observation. In machine learning, AUC is usually seen as the
  preferred evaluative criteria for a model (over accuracy) for
  classification models. This means that AUC is not an output for a
  Gaussian regression, but is output for classification models like binomial. 

  Confusion Matrix: the accuracy of the classifier can be evaluated
  from the confusion matrix, which reports actual versus predicted
  classifications, and the error rates of both.

Expert Settings
"""""""""""""""      
  Expert settings can be accessed by checking the tic box at the bottom of the model page. 

  Standardize is an option that transforms variables into
  standardized variables, each with mean 0 and unit
  variance. Variables and coefficients are now expressed in terms of
  their relative position to 0, and in standard units. 

  Threshold is an option only for binomial models that allows the user
  to define the degree to which they prefer to weight the sensitivity
  (the proportion of correctly classified 1s) and specificity (the
  proportion of correctly classified 0s). The default option is joint
  optimization for the overall classification rate. Changing this will
  alter the confusion matrix and the AUC. 

  LSM solver: LSM stands for Least Squares Method. Least squares is
  the optimization criterion for the model residuals. 

  Beta epsilon: Precision of the vector of coefficients. Computation
  stops when the maximal difference between two beta vectors is below
  than Beta epsilon

Validate GLM 
"""""""""""""

  After running the GLM Model, a .hex key is generated.

#.  Select the "Validate on Another Dataset" option in the horizontal
    menu at the top of your results page. You can also access this at
    a later time by going to the drop down menu "Score" and selecting GLM.

#.  In the validation generation page enter the .hex key for the model
    you wish to validate in the model key field.

#.  In the key field enter the .hex for a testing data set matching
    the structure of your training data set. 

#.  Push the Submit button. 


Cross Validation
""""""""""""""""

The model stated  as a the result of a GLM analysis in H2O can be
presented with cross validated models at the user's request. The
coefficients presented in the result model are independent of those in
any of the cross validated models, and are generated via least squares
on the full data set. Cross validated models are generated by taking a 90%
random subsample of the data, training a model, and testing that model
on the remaining 10%. This process is repeated as many times as the
user specifies in the Nfolds field during model specification. 


	

